{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P.S.  \n",
    "Загрузка и обоснование датасета и метрик в [lab1.ipynb](lab1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая и линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Задача классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем либы\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузим датасет "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 строк датасета для классификации:\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n",
      "\n",
      "Размер датасета: (1599, 12)\n"
     ]
    }
   ],
   "source": [
    "path = 'winequality-red.csv'\n",
    "data_class = pd.read_csv(path)\n",
    "\n",
    "print(\"Первые 5 строк датасета для классификации:\")\n",
    "print(data_class.head())\n",
    "print(f\"\\nРазмер датасета: {data_class.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (по аналогии с 1 лабой) создаем целевую переменную для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Распределение качества вина:\n",
      "wine_quality\n",
      "good    855\n",
      "bad     744\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_class['wine_quality'] = data_class['quality'].apply(lambda x: 'good' if x >= 6 else 'bad')\n",
    "data_class = data_class.drop('quality', axis=1)\n",
    "\n",
    "print(\"\\nРаспределение качества вина:\")\n",
    "print(data_class['wine_quality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разделим датасет на признаки и целевую переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_class.drop('wine_quality', axis=1)\n",
    "y = data_class['wine_quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Масштабируем признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: (1279, 11), Размер тестовой выборки: (320, 11)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}, Размер тестовой выборки: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применим встроенный алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бейзлайн (Logistic Regression):\n",
      "Accuracy: 0.7406\n",
      "F1-Score: 0.7409\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.71      0.74      0.73       149\n",
      "        good       0.77      0.74      0.75       171\n",
      "\n",
      "    accuracy                           0.74       320\n",
      "   macro avg       0.74      0.74      0.74       320\n",
      "weighted avg       0.74      0.74      0.74       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_baseline = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_baseline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_baseline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Бейзлайн (Logistic Regression):\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подберем гиперпараметры для оптимизации бейзлайна\n",
    "\n",
    "##### `C: [0.01, 0.1, 1, 10, 100]`\n",
    "- **Параметр регуляризации** - контролирует силу регуляризации\n",
    "- **Малые значения (0.01-0.1)**: сильная регуляризация, предотвращает переобучение\n",
    "- **Средние значения (1)**: баланс между fitting и регуляризацией (значение по умолчанию)\n",
    "- **Большие значения (10-100)**: слабая регуляризация, модель ближе к обычной MLE\n",
    "- **Логарифмическая шкала**: эффективный поиск по порядкам величин\n",
    "\n",
    "##### `solver: ['liblinear', 'lbfgs', 'sag']`\n",
    "- **liblinear**: эффективен для небольших датасетов, поддерживает L1 и L2\n",
    "- **lbfgs**: стабильный алгоритм, хорош для небольших данных, только L2\n",
    "- **sag**: стохастический метод, эффективен для больших данных, только L2\n",
    "- Покрытие разных сценариев размера данных и вычислительных потребностей\n",
    "\n",
    "##### `penalty: ['l2']`\n",
    "- **L2 регуляризация (Ridge)**: сплошное сглаживание коэффициентов\n",
    "- **Не включает L1**: так как не все солверы поддерживают L1 (lbfgs, sag - только L2)\n",
    "- **Фокус на стабильность**: L2 обычно более стабилен и менее склонен к переобучению\n",
    "\n",
    "##### Общая стратегия\n",
    "Баланс между силой регуляризации (C) и выбором эффективного алгоритма оптимизации (solver) для разных характеристик данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Лучшие параметры: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs', 'sag'],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Лучшие параметры: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение с подобранными гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Улучшенный бейзлайн:\n",
      "Accuracy: 0.7375\n",
      "F1-Score: 0.7378\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.71      0.74      0.73       149\n",
      "        good       0.77      0.73      0.75       171\n",
      "\n",
      "    accuracy                           0.74       320\n",
      "   macro avg       0.74      0.74      0.74       320\n",
      "weighted avg       0.74      0.74      0.74       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_lr = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_lr.predict(X_test)\n",
    "\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "f1_best = f1_score(y_test, y_pred_best, average='weighted')\n",
    "\n",
    "print(\"Улучшенный бейзлайн:\")\n",
    "print(f\"Accuracy: {accuracy_best:.4f}\")\n",
    "print(f\"F1-Score: {f1_best:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Имплементация алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Имплементация Custom Logistic Regression:\n",
      "Accuracy: 0.7375\n",
      "F1-Score: 0.7378\n",
      "Custom Logistic Regression с улучшенными параметрами:\n",
      "Accuracy: 0.7406\n",
      "F1-Score: 0.7409\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.70      0.75      0.73       149\n",
      "        good       0.77      0.73      0.75       171\n",
      "\n",
      "    accuracy                           0.74       320\n",
      "   macro avg       0.74      0.74      0.74       320\n",
      "weighted avg       0.74      0.74      0.74       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class CustomLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        y_encoded = self._one_hot_encode(y)\n",
    "        self.weights = np.zeros((X.shape[1], len(self.classes_)))\n",
    "        self.bias = np.zeros(len(self.classes_))\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            probabilities = self._softmax(linear_model)\n",
    "            dw = np.dot(X.T, (probabilities - y_encoded)) / X.shape[0]\n",
    "            db = np.sum(probabilities - y_encoded, axis=0) / X.shape[0]\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        probabilities = self._softmax(linear_model)\n",
    "        predictions = np.argmax(probabilities, axis=1)\n",
    "        return self.classes_[predictions]\n",
    "\n",
    "    def _softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def _one_hot_encode(self, y):\n",
    "        y_encoded = np.zeros((y.shape[0], len(self.classes_)))\n",
    "        for idx, class_ in enumerate(self.classes_):\n",
    "            y_encoded[:, idx] = (y == class_).astype(float)\n",
    "        return y_encoded\n",
    "\n",
    "custom_lr = CustomLogisticRegression()\n",
    "custom_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_custom = custom_lr.predict(X_test)\n",
    "\n",
    "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
    "f1_custom = f1_score(y_test, y_pred_custom, average='weighted')\n",
    "\n",
    "print(\"Имплементация Custom Logistic Regression:\")\n",
    "print(f\"Accuracy: {accuracy_custom:.4f}\")\n",
    "print(f\"F1-Score: {f1_custom:.4f}\")\n",
    "\n",
    "custom_lr_improved = CustomLogisticRegression(\n",
    "    learning_rate=0.1, \n",
    "    n_iterations=1000\n",
    ")\n",
    "custom_lr_improved.fit(X_train, y_train)\n",
    "y_pred_custom_improved = custom_lr_improved.predict(X_test)\n",
    "\n",
    "accuracy_custom_improved = accuracy_score(y_test, y_pred_custom_improved)\n",
    "f1_custom_improved = f1_score(y_test, y_pred_custom_improved, average='weighted')\n",
    "\n",
    "print(\"Custom Logistic Regression с улучшенными параметрами:\")\n",
    "print(f\"Accuracy: {accuracy_custom_improved:.4f}\")\n",
    "print(f\"F1-Score: {f1_custom_improved:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнение полученных результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение результатов для задачи классификации:\n",
      "Бейзлайн Accuracy: 0.7406, Улучшенный Accuracy: 0.7375, Custom Accuracy: 0.7375\n",
      "Бейзлайн F1-Score: 0.7409, Улучшенный F1-Score: 0.7378, Custom F1-Score: 0.7378\n"
     ]
    }
   ],
   "source": [
    "print(\"Сравнение результатов для задачи классификации:\")\n",
    "print(f\"Бейзлайн Accuracy: {accuracy:.4f}, Улучшенный Accuracy: {accuracy_best:.4f}, Custom Accuracy: {accuracy_custom:.4f}\")\n",
    "print(f\"Бейзлайн F1-Score: {f1:.4f}, Улучшенный F1-Score: {f1_best:.4f}, Custom F1-Score: {f1_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Задача регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 строк датасета для регрессии:\n",
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n",
      "\n",
      "Размер датасета: (17379, 17)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# загружаем данные\n",
    "path = 'hour.csv'\n",
    "data_reg = pd.read_csv(path)\n",
    "\n",
    "print(\"Первые 5 строк датасета для регрессии:\")\n",
    "print(data_reg.head())\n",
    "print(f\"\\nРазмер датасета: {data_reg.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Разделим данные на тестовую и обучающую выборку и масштабирование признаков "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Размер обучающей выборки: (13903, 13), Размер тестовой выборки: (3476, 13)\n",
      "Используемые признаки: ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'registered']\n"
     ]
    }
   ],
   "source": [
    "# убрал дату в строковом представлении (есть дата в числовых колонках), так же число, которое предсказываем (cnt)\n",
    "useful_columns = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', \n",
    "                  'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'registered']\n",
    "\n",
    "# Разделим данные на тестовую и обучающую выборку\n",
    "X = data_reg[useful_columns]\n",
    "y = data_reg['cnt']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nРазмер обучающей выборки: {X_train.shape}, Размер тестовой выборки: {X_test.shape}\")\n",
    "print(f\"Используемые признаки: {list(X.columns)}\")\n",
    "\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_scaled = scaler_reg.fit_transform(X_train)\n",
    "X_test_scaled = scaler_reg.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение бейзлайна и оценка модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бейзлайн (Linear Regression):\n",
      "MAE: 22.0337, MSE: 1057.7405, R^2: 0.9666\n"
     ]
    }
   ],
   "source": [
    "lr_baseline = LinearRegression()\n",
    "lr_baseline.fit(X_train_scaled, y_train)\n",
    "y_pred_reg = lr_baseline.predict(X_test_scaled)\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, mse, r2\n",
    "\n",
    "print(\"Бейзлайн (Linear Regression):\")\n",
    "mae_baseline, mse_baseline, r2_baseline = evaluate_model(y_test, y_pred_reg)\n",
    "print(f\"MAE: {mae_baseline:.4f}, MSE: {mse_baseline:.4f}, R^2: {r2_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор гиперпараметров для оптимизации бейзлайна \n",
    "\n",
    "##### `alpha: [0.01, 0.1, 1, 10, 100]`\n",
    "- **Параметр регуляризации** - контролирует силу L2-регуляризации\n",
    "- **Малые значения (0.01-0.1)**: слабая регуляризация, модель близка к обычной линейной регрессии\n",
    "- **Средние значения (1)**: умеренная регуляризация, баланс между bias и variance\n",
    "- **Большие значения (10-100)**: сильная регуляризация, коэффициенты сильно сжимаются к нулю\n",
    "- **Логарифмическая шкала**: эффективный поиск по разным порядкам величины регуляризации  \n",
    "\n",
    "Берем только alpha тк это ключевой параметр, определяющий силу регуляризации. Для Ridge регрессии часто достаточно подобрать только alpha, а так же помогает уменьшению пространства поиска ускоряет GridSearch \n",
    "\n",
    "### Общая стратегия\n",
    "Систематический поиск оптимальной силы регуляризации от очень слабой до очень сильной через логарифмическую шкалу значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Лучший alpha для Ridge регрессии: 10\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"alpha\": [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_ridge = GridSearchCV(Ridge(), param_grid, cv=5, scoring=\"r2\", verbose=1)\n",
    "grid_ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_alpha = grid_ridge.best_params_[\"alpha\"]\n",
    "print(f\"Лучший alpha для Ridge регрессии: {best_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение с подобранными гиперпараметрами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Улучшенная модель (Ridge Regression):\n",
      "MAE: 22.0182, MSE: 1057.5906, R^2: 0.9666\n"
     ]
    }
   ],
   "source": [
    "ridge_optimized = Ridge(alpha=best_alpha)\n",
    "ridge_optimized.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge_optimized.predict(X_test_scaled)\n",
    "\n",
    "print(\"Улучшенная модель (Ridge Regression):\")\n",
    "mae_ridge, mse_ridge, r2_ridge = evaluate_model(y_test, y_pred_ridge)\n",
    "print(f\"MAE: {mae_ridge:.4f}, MSE: {mse_ridge:.4f}, R^2: {r2_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Имплементация алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Linear Regression:\n",
      "MAE: 22.0337, MSE: 1057.6337, R^2: 0.9666\n",
      "Улучшенный Custom Ridge Regression:\n",
      "MAE: 22.0197, MSE: 1057.5042, R^2: 0.9666\n"
     ]
    }
   ],
   "source": [
    "class CustomRidgeRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000, alpha=1.0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.alpha = alpha  # параметр регуляризации\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.m = X.shape[0]\n",
    "        self.n = X.shape[1]\n",
    "        self.weights = np.zeros(self.n)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            y_predicted = self._predict(X)\n",
    "            # Добавляем регуляризацию L2\n",
    "            dw = -(2/self.m) * np.dot(X.T, (y - y_predicted)) + (2*self.alpha/self.m) * self.weights\n",
    "            db = -(2/self.m) * np.sum(y - y_predicted)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self._predict(X)\n",
    "\n",
    "    def _predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "\n",
    "custom_lr = CustomRidgeRegression()\n",
    "custom_lr.fit(X_train_scaled, y_train)\n",
    "y_pred_custom = custom_lr.predict(X_test_scaled)\n",
    "\n",
    "mae_custom, mse_custom, r2_custom = evaluate_model(y_test, y_pred_custom)\n",
    "\n",
    "print(\"Custom Linear Regression:\")\n",
    "print(f\"MAE: {mae_custom:.4f}, MSE: {mse_custom:.4f}, R^2: {r2_custom:.4f}\")\n",
    "\n",
    "custom_ridge = CustomRidgeRegression(learning_rate=0.01, n_iterations=1000, alpha=best_alpha)\n",
    "custom_ridge.fit(X_train_scaled, y_train)\n",
    "y_pred_custom_ridge = custom_ridge.predict(X_test_scaled)\n",
    "\n",
    "mae_custom_ridge, mse_custom_ridge, r2_custom_ridge = evaluate_model(y_test, y_pred_custom_ridge)\n",
    "\n",
    "print(\"Улучшенный Custom Ridge Regression:\")\n",
    "print(f\"MAE: {mae_custom_ridge:.4f}, MSE: {mse_custom_ridge:.4f}, R^2: {r2_custom_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнение всех полученных результатов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сравнение результатов для задачи регрессии:\n",
      "Бейзлайн MAE: 22.0337, Улучшенный MAE: 22.0182, Custom MAE: 22.0337, Улучшенный Custom MAE: 22.0197\n",
      "Бейзлайн MSE: 1057.7405, Улучшенный MSE: 1057.5906, Custom MSE: 1057.6337, Улучшенный Custom  MSE: 1057.5042\n",
      "Бейзлайн R^2: 0.9666, Улучшенный R^2: 0.9666, Custom R^2: 0.9666, Улучшенный Custom R^2: 0.9666\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСравнение результатов для задачи регрессии:\")\n",
    "print(f\"Бейзлайн MAE: {mae_baseline:.4f}, Улучшенный MAE: {mae_ridge:.4f}, Custom MAE: {mae_custom:.4f}, Улучшенный Custom MAE: {mae_custom_ridge:.4f}\")\n",
    "print(f\"Бейзлайн MSE: {mse_baseline:.4f}, Улучшенный MSE: {mse_ridge:.4f}, Custom MSE: {mse_custom:.4f}, Улучшенный Custom  MSE: {mse_custom_ridge:.4f}\")\n",
    "print(f\"Бейзлайн R^2: {r2_baseline:.4f}, Улучшенный R^2: {r2_ridge:.4f}, Custom R^2: {r2_custom:.4f}, Улучшенный Custom R^2: {r2_custom_ridge:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

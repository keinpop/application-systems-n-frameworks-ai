{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Задача классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 строк датасета для классификации:\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n",
      "\n",
      "Размер датасета: (1599, 12)\n"
     ]
    }
   ],
   "source": [
    "path = 'winequality-red.csv'\n",
    "data_class = pd.read_csv(path)\n",
    "\n",
    "print(\"Первые 5 строк датасета для классификации:\")\n",
    "print(data_class.head())\n",
    "print(f\"\\nРазмер датасета: {data_class.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем целевую переменную для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Распределение качества вина:\n",
      "wine_quality\n",
      "good    855\n",
      "bad     744\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_class['wine_quality'] = data_class['quality'].apply(lambda x: 'good' if x >= 6 else 'bad')\n",
    "data_class = data_class.drop('quality', axis=1)\n",
    "\n",
    "print(\"\\nРаспределение качества вина:\")\n",
    "print(data_class['wine_quality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделим датасет на признаки и целевую переменную и масштабирование признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: (1279, 11), Размер тестовой выборки: (320, 11)\n"
     ]
    }
   ],
   "source": [
    "X = data_class.drop('wine_quality', axis=1)\n",
    "y = data_class['wine_quality']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}, Размер тестовой выборки: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применим встроенный алгоритм для случайного леса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бейзлайн Random Forest:\n",
      "Accuracy: 0.8063\n",
      "F1-Score: 0.8064\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.78      0.81      0.80       149\n",
      "        good       0.83      0.80      0.82       171\n",
      "\n",
      "    accuracy                           0.81       320\n",
      "   macro avg       0.81      0.81      0.81       320\n",
      "weighted avg       0.81      0.81      0.81       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_baseline = RandomForestClassifier(random_state=42)\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_baseline = rf_baseline.predict(X_test)\n",
    "\n",
    "accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "f1_baseline = f1_score(y_test, y_pred_baseline, average='weighted')\n",
    "\n",
    "print(\"Бейзлайн Random Forest:\")\n",
    "print(f\"Accuracy: {accuracy_baseline:.4f}\")\n",
    "print(f\"F1-Score: {f1_baseline:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подберем гиперпараметры для улучшения бейзлайна\n",
    "\n",
    "\n",
    "##### `n_estimators: [50, 100, 200]`\n",
    "- **Количество деревьев в ансамбле** - баланс точности и вычислительной стоимости\n",
    "- **50**: быстрая тренировка, достаточная для начальной оценки\n",
    "- **100**: стандартный выбор, хороший баланс производительности и точности\n",
    "- **200**: большее разнообразие, потенциально лучшая обобщающая способность\n",
    "\n",
    "##### `max_depth: [None, 10, 20, 30]`\n",
    "- **Контроль глубины деревьев** - от полностью grown до ограниченных\n",
    "- **None**: неограниченная глубина (полностью grown деревья)\n",
    "- **10**: сильно ограниченные деревья, высокая bias, низкая variance\n",
    "- **20**: умеренное ограничение, баланс сложности\n",
    "- **30**: минимальное ограничение, близко к полным деревьям\n",
    "\n",
    "##### `min_samples_split: [2, 5, 10]`\n",
    "- **Минимальные samples для разделения** - контроль переобучения\n",
    "- **2**: максимальная детализация (риск переобучения)\n",
    "- **5**: умеренное ограничение, хороший компромисс\n",
    "- **10**: сильное ограничение, устойчивость к шуму\n",
    "\n",
    "##### `min_samples_leaf: [1, 2, 4]`\n",
    "- **Минимальные samples в листьях** - стабилизация предсказаний\n",
    "- **1**: максимальная гибкость (может ловить шум)\n",
    "- **2**: стандартный выбор для баланса\n",
    "- **4**: сглаженные предсказания, устойчивость к выбросам\n",
    "\n",
    "##### Общая стратегия\n",
    "Баланс между разнообразием ансамбля (n_estimators) и контролем сложности отдельных деревьев, что является ключевым для эффективности случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Лучшие параметры: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(f\"Лучшие параметры: {best_params_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проведем обучение улучшенной модели и посчитаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Улучшенный бейзлайн Random Forest:\n",
      "Accuracy: 0.8125\n",
      "F1-Score: 0.8126\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.79      0.81      0.80       149\n",
      "        good       0.83      0.82      0.82       171\n",
      "\n",
      "    accuracy                           0.81       320\n",
      "   macro avg       0.81      0.81      0.81       320\n",
      "weighted avg       0.81      0.81      0.81       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
    "f1_best_rf = f1_score(y_test, y_pred_best_rf, average='weighted')\n",
    "\n",
    "print(\"Улучшенный бейзлайн Random Forest:\")\n",
    "print(f\"Accuracy: {accuracy_best_rf:.4f}\")\n",
    "print(f\"F1-Score: {f1_best_rf:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_best_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуем собственную имплементацию алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, \n",
    "                 min_samples_leaf=1, max_features='auto', random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "        self.feature_indices = [] \n",
    "        \n",
    "    def _get_max_features(self, n_features):\n",
    "        \"\"\"Определяем количество признаков для каждого дерева\"\"\"\n",
    "        if self.max_features == 'auto':\n",
    "            return int(np.sqrt(n_features))\n",
    "        elif self.max_features == 'sqrt':\n",
    "            return int(np.sqrt(n_features))\n",
    "        elif self.max_features == 'log2':\n",
    "            return int(np.log2(n_features))\n",
    "        elif isinstance(self.max_features, int):\n",
    "            return min(self.max_features, n_features)\n",
    "        elif isinstance(self.max_features, float):\n",
    "            return int(self.max_features * n_features)\n",
    "        else:\n",
    "            return n_features\n",
    "    \n",
    "    def _bootstrap_sample(self, X, y, n_features):\n",
    "        \"\"\"Bootstrap sampling + случайный выбор признаков\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Bootstrap sampling\n",
    "        sample_indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        X_bootstrap = X[sample_indices]\n",
    "        y_bootstrap = y[sample_indices]\n",
    "        \n",
    "        # Случайный выбор признаков\n",
    "        feature_indices = np.random.choice(n_features, n_features, replace=False)\n",
    "        selected_features = feature_indices[:self._get_max_features(n_features)]\n",
    "        \n",
    "        return X_bootstrap[:, selected_features], y_bootstrap, selected_features\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        self.feature_indices = []\n",
    "        X_array = np.array(X)\n",
    "        y_array = np.array(y)\n",
    "        n_samples, n_features = X_array.shape\n",
    "        \n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "            \n",
    "        for i in range(self.n_estimators):\n",
    "            # Получаем bootstrap sample и случайные признаки\n",
    "            X_sample, y_sample, selected_features = self._bootstrap_sample(X_array, y_array, n_features)\n",
    "            \n",
    "            tree = DecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                random_state=self.random_state + i if self.random_state is not None else None\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "            self.feature_indices.append(selected_features)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X_array = np.array(X)\n",
    "        all_predictions = []\n",
    "        \n",
    "        for tree, features in zip(self.trees, self.feature_indices):\n",
    "            # используем только те призанки, которые использовались при обучении дерева\n",
    "            X_subset = X_array[:, features]\n",
    "            predictions = tree.predict(X_subset)\n",
    "            all_predictions.append(predictions)\n",
    "        \n",
    "        # Голосование большинством\n",
    "        tree_predictions = np.array(all_predictions)\n",
    "        final_predictions = []\n",
    "        \n",
    "        for sample_predictions in tree_predictions.T:\n",
    "            most_common = Counter(sample_predictions).most_common(1)[0][0]\n",
    "            final_predictions.append(most_common)\n",
    "            \n",
    "        return np.array(final_predictions)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X_array = np.array(X)\n",
    "        all_probas = []\n",
    "        \n",
    "        for tree, features in zip(self.trees, self.feature_indices):\n",
    "            X_subset = X_array[:, features]\n",
    "            try:\n",
    "                probas = tree.predict_proba(X_subset)\n",
    "                all_probas.append(probas)\n",
    "            except AttributeError:\n",
    "                # Если дерево не поддерживает predict_proba, используем one-hot encoding\n",
    "                predictions = tree.predict(X_subset)\n",
    "                probas = np.zeros((len(predictions), len(tree.classes_)))\n",
    "                for i, pred in enumerate(predictions):\n",
    "                    class_idx = np.where(tree.classes_ == pred)[0][0]\n",
    "                    probas[i, class_idx] = 1.0\n",
    "                all_probas.append(probas)\n",
    "        \n",
    "        # Усредняем вероятности\n",
    "        avg_probas = np.mean(all_probas, axis=0)\n",
    "        return avg_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим метрики на дефолтных и улучшенных параметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Random Forest (базовый):\n",
      "Accuracy: 0.8000\n",
      "F1-Score: 0.8002\n",
      "Custom Random Forest (улучшенный):\n",
      "Accuracy: 0.7969\n",
      "F1-Score: 0.7970\n"
     ]
    }
   ],
   "source": [
    "custom_rf = CustomRandomForest(n_estimators=100, max_depth=None, random_state=42)\n",
    "custom_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_custom_rf = custom_rf.predict(X_test)\n",
    "\n",
    "accuracy_custom_rf = accuracy_score(y_test, y_pred_custom_rf)\n",
    "f1_custom_rf = f1_score(y_test, y_pred_custom_rf, average='weighted')\n",
    "\n",
    "print(\"Custom Random Forest (базовый):\")\n",
    "print(f\"Accuracy: {accuracy_custom_rf:.4f}\")\n",
    "print(f\"F1-Score: {f1_custom_rf:.4f}\")\n",
    "\n",
    "# Кастомный Random Forest с улучшенными параметрами\n",
    "custom_rf_improved = CustomRandomForest(\n",
    "    n_estimators=best_params_rf['n_estimators'],\n",
    "    max_depth=best_params_rf['max_depth'],\n",
    "    min_samples_split=best_params_rf['min_samples_split'],\n",
    "    min_samples_leaf=best_params_rf['min_samples_leaf'],\n",
    "    max_features='sqrt', \n",
    "    random_state=42\n",
    ")\n",
    "custom_rf_improved.fit(X_train, y_train)\n",
    "\n",
    "y_pred_custom_rf_improved = custom_rf_improved.predict(X_test)\n",
    "\n",
    "accuracy_custom_rf_improved = accuracy_score(y_test, y_pred_custom_rf_improved)\n",
    "f1_custom_rf_improved = f1_score(y_test, y_pred_custom_rf_improved, average='weighted')\n",
    "\n",
    "print(\"Custom Random Forest (улучшенный):\")\n",
    "print(f\"Accuracy: {accuracy_custom_rf_improved:.4f}\")\n",
    "print(f\"F1-Score: {f1_custom_rf_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посмотрим на все результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сравнение результатов для задачи классификации:\n",
      "Бейзлайн Accuracy: 0.8063, Улучшенный Accuracy: 0.8125, Custom RF Accuracy: 0.8000, Custom RF улучшенный Accuracy: 0.7969\n",
      "Бейзлайн F1-Score: 0.8064, Улучшенный F1-Score: 0.8126, Custom RF F1-Score: 0.8002, Custom RF улучшенный F1-Score: 0.7970\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСравнение результатов для задачи классификации:\")\n",
    "print(f\"Бейзлайн Accuracy: {accuracy_baseline:.4f}, Улучшенный Accuracy: {accuracy_best_rf:.4f}, Custom RF Accuracy: {accuracy_custom_rf:.4f}, Custom RF улучшенный Accuracy: {accuracy_custom_rf_improved:.4f}\")\n",
    "print(f\"Бейзлайн F1-Score: {f1_baseline:.4f}, Улучшенный F1-Score: {f1_best_rf:.4f}, Custom RF F1-Score: {f1_custom_rf:.4f}, Custom RF улучшенный F1-Score: {f1_custom_rf_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Задача регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем нужные библиотеки\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Первые 5 строк датасета для регрессии:\n",
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    }
   ],
   "source": [
    "path = 'hour.csv'\n",
    "data_reg = pd.read_csv(path)\n",
    "\n",
    "print(\"\\nПервые 5 строк датасета для регрессии:\")\n",
    "print(data_reg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделяем на признаки и целевую переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Используемые признаки: ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
      "Размер X: (17379, 12)\n"
     ]
    }
   ],
   "source": [
    "# убрал дату в строковом представлении (есть дата в числовых колонках), так же число, которое предсказываем (cnt)\n",
    "useful_columns = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', \n",
    "                  'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "\n",
    "# Разделим данные на тестовую и обучающую выборку\n",
    "X = data_reg[useful_columns]\n",
    "y = data_reg['cnt']\n",
    "\n",
    "print(f\"\\nИспользуемые признаки: {list(X.columns)}\")\n",
    "print(f\"Размер X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делим и масштабируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: (13903, 12), Размер тестовой выборки: (3476, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}, Размер тестовой выборки: {X_test.shape}\")\n",
    "\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_scaled = scaler_reg.fit_transform(X_train)\n",
    "X_test_scaled = scaler_reg.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение бейзлайна и оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Бейзлайн Random Forest Regressor:\n",
      "MAE: 24.8923, MSE: 1769.2754, R^2: 0.9441\n"
     ]
    }
   ],
   "source": [
    "rf_baseline = RandomForestRegressor(random_state=42)\n",
    "rf_baseline.fit(X_train_scaled, y_train)\n",
    "y_pred_reg = rf_baseline.predict(X_test_scaled)\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, mse, r2\n",
    "\n",
    "print(\"\\nБейзлайн Random Forest Regressor:\")\n",
    "mae_baseline, mse_baseline, r2_baseline = evaluate_model(y_test, y_pred_reg)\n",
    "print(f\"MAE: {mae_baseline:.4f}, MSE: {mse_baseline:.4f}, R^2: {r2_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбираем гиперпараметры для улучшения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Лучшие параметры: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"r2\",\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params_reg = grid_search.best_params_\n",
    "print(f\"Лучшие параметры: {best_params_reg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модели с подобранными гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Улучшенный Random Forest Regressor:\n",
      "MAE: 24.7033, MSE: 1746.1439, R²: 0.9449\n"
     ]
    }
   ],
   "source": [
    "rf_optimized = grid_search.best_estimator_\n",
    "rf_optimized.fit(X_train_scaled, y_train)\n",
    "y_pred_optimized = rf_optimized.predict(X_test_scaled)\n",
    "\n",
    "mae_optimized, mse_optimized, r2_optimized = evaluate_model(y_test, y_pred_optimized)\n",
    "\n",
    "print(\"\\nУлучшенный Random Forest Regressor:\")\n",
    "print(f\"MAE: {mae_optimized:.4f}, MSE: {mse_optimized:.4f}, R²: {r2_optimized:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуем свой алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRandomForestRegressor:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "\n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "            \n",
    "        for i in range(self.n_estimators):\n",
    "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                random_state=self.random_state + i if self.random_state is not None else None\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Random Forest Regressor (базовый):\n",
      "MAE: 24.9830, MSE: 1775.5030, R²: 0.9439\n",
      "\n",
      "Custom Random Forest Regressor (улучшенный):\n",
      "MAE: 24.8189, MSE: 1751.6846, R²: 0.9447\n"
     ]
    }
   ],
   "source": [
    "custom_rf_reg = CustomRandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n",
    "custom_rf_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_custom_reg = custom_rf_reg.predict(X_test_scaled)\n",
    "\n",
    "mae_custom, mse_custom, r2_custom = evaluate_model(y_test, y_pred_custom_reg)\n",
    "\n",
    "print(\"\\nCustom Random Forest Regressor (базовый):\")\n",
    "print(f\"MAE: {mae_custom:.4f}, MSE: {mse_custom:.4f}, R²: {r2_custom:.4f}\")\n",
    "\n",
    "custom_rf_reg_improved = CustomRandomForestRegressor(\n",
    "    n_estimators=best_params_reg['n_estimators'],\n",
    "    max_depth=best_params_reg['max_depth'],\n",
    "    min_samples_split=best_params_reg['min_samples_split'],\n",
    "    min_samples_leaf=best_params_reg['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "custom_rf_reg_improved.fit(X_train_scaled, y_train)\n",
    "y_pred_custom_reg_improved = custom_rf_reg_improved.predict(X_test_scaled)\n",
    "\n",
    "mae_custom_improved, mse_custom_improved, r2_custom_improved = evaluate_model(y_test, y_pred_custom_reg_improved)\n",
    "\n",
    "print(\"\\nCustom Random Forest Regressor (улучшенный):\")\n",
    "print(f\"MAE: {mae_custom_improved:.4f}, MSE: {mse_custom_improved:.4f}, R²: {r2_custom_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на все результаты суммарно и сравним их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сравнение результатов для задачи регрессии:\n",
      "Бейзлайн MAE: 24.8923, Улучшенный MAE: 24.7033, Custom RF MAE: 24.9830, Custom RF улучшенный MAE: 24.8189\n",
      "Бейзлайн MSE: 1769.2754, Улучшенный MSE: 1746.1439, Custom RF MSE: 1775.5030, Custom RF улучшенный MSE: 1751.6846\n",
      "Бейзлайн R^2: 0.9441, Улучшенный R^2: 0.9449, Custom RF R^2: 0.9439, Custom RF улучшенный R^2: 0.9447\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСравнение результатов для задачи регрессии:\")\n",
    "print(f\"Бейзлайн MAE: {mae_baseline:.4f}, Улучшенный MAE: {mae_optimized:.4f}, Custom RF MAE: {mae_custom:.4f}, Custom RF улучшенный MAE: {mae_custom_improved:.4f}\")\n",
    "print(f\"Бейзлайн MSE: {mse_baseline:.4f}, Улучшенный MSE: {mse_optimized:.4f}, Custom RF MSE: {mse_custom:.4f}, Custom RF улучшенный MSE: {mse_custom_improved:.4f}\")\n",
    "print(f\"Бейзлайн R^2: {r2_baseline:.4f}, Улучшенный R^2: {r2_optimized:.4f}, Custom RF R^2: {r2_custom:.4f}, Custom RF улучшенный R^2: {r2_custom_improved:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
